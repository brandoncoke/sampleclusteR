label_score[label_score == 0]= "Control"
label_score[label_score == 1]= "Treated upregulated"
label_score[label_score == 2]= "Treated downregulated"
}else{
label_score= rep("Unknown", length(label_score))
}
meta_data_frame$group= clusters
meta_data_frame$sample_type= label_score
exp_design_frame= get.clusters.as.frame(column_clusters)
cluster_names= get.cluster.titles(exp_design_frame)
meta_data_frame$group_name= cluster_names[clusters]
if(concise){
return(
data.frame(
"sample"= paste0("Sample_", 1:nrow(meta_data_frame)),
"clustered_name"= cluster_names[clusters],
"group"= meta_data_frame[ , "group"]
)
)
}else{
return(meta_data_frame)
}
exp_design_frame
get.cluster.titles(exp_design_frame)
#import sdrf metadata frame
metadata= read.delim(sdrf_loc, sep= "\t", header = T)
metadata[is.na(metadata)]= ""
#get the sample names
sample_source= metadata$Source.Name
#remove uneccessary columns
metadata= metadata[!grepl("id|file|accession|source[.]Name|scan[.]|comment[.]", colnames(metadata),
ignore.case= T)]
#cols_all_unique= apply(metadata, 2, function(x){
#  round(length(x)*broad_cluster_thres) > length(unique(x)) &
#    length(unique(x)) != 1
#cut down on redundancy- select columns where the are multiple values
cols_all_unique= apply(metadata, 2, function(x){
length(unique(x)) != 1
})
cluster_frame= metadata[,cols_all_unique]
#then remove columns where the same value is provided for a given row
nonredundant_col_indices= as.list(apply(cluster_frame, 1, function(x){which(!duplicated(x))}))
nonredundant_col_indices= unique(unlist(nonredundant_col_indices))
cluster_frame= cluster_frame[, nonredundant_col_indices]
#drop columns with sample ids or file ids to make automated clusters more
#readable
cols_to_keep= colnames(cluster_frame)
cluster_frame= metadata[,cols_to_keep]
#append column name i.e. append original column name from sdrf metadata table
for(i in 1:ncol(cluster_frame)){
append_col= colnames(cluster_frame)[i]
append_col= gsub("characteristics.|factor.value",
"",
append_col,
ignore.case = T)
append_col= gsub("[.]",
"_",
append_col,
ignore.case = T)
#upper case first letter
append_col=
paste0(toupper(substr(append_col,1,1)),
substr(append_col,2,nchar(append_col)))
append_col= gsub("^_|_$", "", append_col)
append_col= paste0(append_col, ":_")
cluster_frame[,i]= gsub(" ", "_", paste0(append_col, cluster_frame[,i],
sep= "_"))
}
row.names(cluster_frame)= 1:nrow(cluster_frame)
sdrf_loc= "https://ftp.ebi.ac.uk/biostudies/fire/E-MTAB-/935/E-MTAB-11935/Files/E-MTAB-11935.sdrf.txt"
#import sdrf metadata frame
metadata= read.delim(sdrf_loc, sep= "\t", header = T)
metadata[is.na(metadata)]= ""
#get the sample names
sample_source= metadata$Source.Name
#remove uneccessary columns
metadata= metadata[!grepl("id|file|accession|source[.]Name|scan[.]|comment[.]", colnames(metadata),
ignore.case= T)]
#cols_all_unique= apply(metadata, 2, function(x){
#  round(length(x)*broad_cluster_thres) > length(unique(x)) &
#    length(unique(x)) != 1
#cut down on redundancy- select columns where the are multiple values
cols_all_unique= apply(metadata, 2, function(x){
length(unique(x)) != 1
})
cluster_frame= metadata[,cols_all_unique]
#then remove columns where the same value is provided for a given row
nonredundant_col_indices= as.list(apply(cluster_frame, 1, function(x){which(!duplicated(x))}))
nonredundant_col_indices= unique(unlist(nonredundant_col_indices))
cluster_frame= cluster_frame[, nonredundant_col_indices]
#drop columns with sample ids or file ids to make automated clusters more
#readable
cols_to_keep= colnames(cluster_frame)
cluster_frame= metadata[,cols_to_keep]
#append column name i.e. append original column name from sdrf metadata table
for(i in 1:ncol(cluster_frame)){
append_col= colnames(cluster_frame)[i]
append_col= gsub("characteristics.|factor.value",
"",
append_col,
ignore.case = T)
append_col= gsub("[.]",
"_",
append_col,
ignore.case = T)
#upper case first letter
append_col=
paste0(toupper(substr(append_col,1,1)),
substr(append_col,2,nchar(append_col)))
append_col= gsub("^_|_$", "", append_col)
append_col= paste0(append_col, ":_")
cluster_frame[,i]= gsub(" ", "_", paste0(append_col, cluster_frame[,i],
sep= "_"))
}
row.names(cluster_frame)= 1:nrow(cluster_frame)
clustered_frame= cluster.metadata.frame(cluster_frame,
concise= concise)
clustered_frame$sample= sample_source
clustered_frame
meta_data_frame=cluster_frame
if(!any(columns_to_cluster %in% 1:nrow(meta_data_frame))){
message("No columns specified for clustering- clustering by all columns- provide a numeric list with columns_to_cluster")
columns_to_cluster= 1:ncol(meta_data_frame)
columns_to_cluster_unique= apply(meta_data_frame, 2, function(x){
length(unique(x)) != 1
})
if(sum(columns_to_cluster_unique) == 0){
stop("All samples unique cannot cluster- need a another column")
}
columns_to_cluster= as.numeric(which(columns_to_cluster_unique))
if(length(columns_to_cluster) > 1){
sample_labels= apply(meta_data_frame[, columns_to_cluster_unique], 1,
paste, collapse = "_")
}else{
sample_labels= meta_data_frame[, columns_to_cluster_unique]
}
if(length(sample_labels) != length(unique(sample_labels))){
sample_labels= paste0(sample_labels, "_sample_", 1:length(sample_labels))
}
}else{
if(length(columns_to_cluster)> 2){
sample_labels=
as.character(apply(meta_data_frame[, columns_to_cluster], 1, paste0, collapse = "_"))
}else{
sample_labels= meta_data_frame[, columns_to_cluster]
}
sample_labels= paste0(sample_labels, "_sample_", 1:length(sample_labels))
}
column_clusters= title.clustering(
sample_labels, words_only= F)
if(length(column_clusters) > nrow(meta_data_frame)*.75){
message("Sample ids are likely to be present- making clustering more broad")
column_clusters= title.clustering(
sample_labels,
words_only= T)
}
#assign samples with group numbers
clusters= as.integer(lapply(sample_labels, function(x){
group= NULL
for(i in 1:length(column_clusters)){
group= c(group, x %in% unlist(column_clusters[i]))
}
which(group)
}))
#detecting control and treated samples
label_score= as.integer(lapply(sample_labels, get_score_labels))
if(any(label_score == 1) | any(label_score == 2)){
label_score[label_score == 0]= "Control"
label_score[label_score == 1]= "Treated upregulated"
label_score[label_score == 2]= "Treated downregulated"
}else{
label_score= rep("Unknown", length(label_score))
}
meta_data_frame$group= clusters
meta_data_frame$sample_type= label_score
exp_design_frame= get.clusters.as.frame(column_clusters)
exp_design_frame
sdrf_loc="https://ftp.ebi.ac.uk/biostudies/fire/E-GEOD-/805/E-GEOD-67805/Files/E-GEOD-67805.sdrf.txt"
#import sdrf metadata frame
metadata= read.delim(sdrf_loc, sep= "\t", header = T)
metadata[is.na(metadata)]= ""
#get the sample names
sample_source= metadata$Source.Name
#remove uneccessary columns
metadata= metadata[!grepl("id|file|accession|source[.]Name|scan[.]|comment[.]", colnames(metadata),
ignore.case= T)]
#cols_all_unique= apply(metadata, 2, function(x){
#  round(length(x)*broad_cluster_thres) > length(unique(x)) &
#    length(unique(x)) != 1
#cut down on redundancy- select columns where the are multiple values
cols_all_unique= apply(metadata, 2, function(x){
length(unique(x)) != 1
})
cluster_frame= metadata[,cols_all_unique]
#then remove columns where the same value is provided for a given row
nonredundant_col_indices= as.list(apply(cluster_frame, 1, function(x){which(!duplicated(x))}))
nonredundant_col_indices= unique(unlist(nonredundant_col_indices))
cluster_frame= cluster_frame[, nonredundant_col_indices]
#drop columns with sample ids or file ids to make automated clusters more
#readable
cols_to_keep= colnames(cluster_frame)
cluster_frame= metadata[,cols_to_keep]
#append column name i.e. append original column name from sdrf metadata table
for(i in 1:ncol(cluster_frame)){
append_col= colnames(cluster_frame)[i]
append_col= gsub("characteristics.|factor.value",
"",
append_col,
ignore.case = T)
append_col= gsub("[.]",
"_",
append_col,
ignore.case = T)
#upper case first letter
append_col=
paste0(toupper(substr(append_col,1,1)),
substr(append_col,2,nchar(append_col)))
append_col= gsub("^_|_$", "", append_col)
append_col= paste0(append_col, ":_")
cluster_frame[,i]= gsub(" ", "_", paste0(append_col, cluster_frame[,i],
sep= "_"))
}
row.names(cluster_frame)= 1:nrow(cluster_frame)
meta_data_frame=cluster_frame
meta_data_frame
if(!any(columns_to_cluster %in% 1:nrow(meta_data_frame))){
message("No columns specified for clustering- clustering by all columns- provide a numeric list with columns_to_cluster")
columns_to_cluster= 1:ncol(meta_data_frame)
columns_to_cluster_unique= apply(meta_data_frame, 2, function(x){
length(unique(x)) != 1
})
if(sum(columns_to_cluster_unique) == 0){
stop("All samples unique cannot cluster- need a another column")
}
columns_to_cluster= as.numeric(which(columns_to_cluster_unique))
if(length(columns_to_cluster) > 1){
sample_labels= apply(meta_data_frame[, columns_to_cluster_unique], 1,
paste, collapse = "_")
}else{
sample_labels= meta_data_frame[, columns_to_cluster_unique]
}
if(length(sample_labels) != length(unique(sample_labels))){
sample_labels= paste0(sample_labels, "_sample_", 1:length(sample_labels))
}
}else{
if(length(columns_to_cluster)> 2){
sample_labels=
as.character(apply(meta_data_frame[, columns_to_cluster], 1, paste0, collapse = "_"))
}else{
sample_labels= meta_data_frame[, columns_to_cluster]
}
sample_labels= paste0(sample_labels, "_sample_", 1:length(sample_labels))
}
column_clusters= title.clustering(
sample_labels, words_only= F)
if(length(column_clusters) > nrow(meta_data_frame)*.75){
message("Sample ids are likely to be present- making clustering more broad")
column_clusters= title.clustering(
sample_labels,
words_only= T)
}
#assign samples with group numbers
clusters= as.integer(lapply(sample_labels, function(x){
group= NULL
for(i in 1:length(column_clusters)){
group= c(group, x %in% unlist(column_clusters[i]))
}
which(group)
}))
#detecting control and treated samples
label_score= as.integer(lapply(sample_labels, get_score_labels))
if(any(label_score == 1) | any(label_score == 2)){
label_score[label_score == 0]= "Control"
label_score[label_score == 1]= "Treated upregulated"
label_score[label_score == 2]= "Treated downregulated"
}else{
label_score= rep("Unknown", length(label_score))
}
meta_data_frame$group= clusters
meta_data_frame$sample_type= label_score
column_clusters
cluster_list
cluster_list= column_clusters
cluster_list=as.list(cluster_list)
cluster_list_lengths= as.integer(lapply(cluster_list,length)) #gets lengths of cluster titles
cluster_list_lengths_max= cluster_list_lengths[which.max(cluster_list_lengths)[1]] #identifies length of cluster title with longest title
cluster_frame= NULL
#cbind the clusters sample names- fill with NA by selecting an indice range outide of length
cluster_list= column_clusters
as.list(cluster_list)
cluster_list=as.list(cluster_list)
cluster_list_lengths= as.integer(lapply(cluster_list,length))
cluster_list_lengths
cluster_list_lengths_max= cluster_list_lengths[which.max(cluster_list_lengths)[1]] #identifies length of cluster title with longest title
cluster_frame= NULL
cluster_list_lengths_max
i=1
a_cluster_list= as.data.frame(cluster_list[i])
a_cluster_list= a_cluster_list[,1]
a_cluster_list= a_cluster_list[1:cluster_list_lengths_max]
a_cluster_list= as.character(a_cluster_list)
cluster_frame=cbind(cluster_frame,a_cluster_list)
colnames(cluster_frame)[i]= paste0("Cluster_",i)
cluster_frame
a_cluster_list
cluster_list
unlist](cluster_list)
unlist(cluster_list)
data.frame(unlist(cluster_list))
t(data.frame(unlist(cluster_list)))
cluster_frame= t(data.frame(unlist(cluster_list)))
cluster_frame
View(cluster_frame)
unlist(cluster_list))
cluster_frame= unlist(cluster_list)
cluster_frame
data.frame(cluster_frame,
cluster_frame)
data.frame(c(cluster_frame,
cluster_frame)
data.frame(c(cluster_frame,
cluster_frame))
t(data.frame(unlist(cluster_list)))
rbind(cluster_frame, cluster_frame)
cluster_frame= t(data.frame(unlist(cluster_list)))
cluster_frame= rbind(cluster_frame, cluster_frame)
cluster_frame= t(data.frame(unlist(cluster_list)))
cluster_frame= rbind(cluster_frame, cluster_frame)
row.names(cluster_frame)= 1:2
colnames(clustered_frame)= paste0("Cluster_",1:ncol(cluster_frame))
View(clustered_frame)
cluster_frame= t(data.frame(unlist(cluster_list)))
cluster_frame= rbind(cluster_frame, cluster_frame)
row.names(cluster_frame)= 1:2
colnames(cluster_frame)= paste0("Cluster_",1:ncol(cluster_frame))
cluster_list=as.list(cluster_list)
cluster_list_lengths= as.integer(lapply(cluster_list,length)) #gets lengths of cluster titles
cluster_list_lengths_max= cluster_list_lengths[which.max(cluster_list_lengths)[1]] #identifies length of cluster title with longest title
cluster_frame= NULL
#cbind the clusters sample names- fill with NA by selecting an indice range outide of length
#issue with output not dataframe with only 1 sample per cluster
if(cluster_list_lengths_max > 1){
for(i in 1:length(cluster_list)){
a_cluster_list= as.data.frame(cluster_list[i])
a_cluster_list= a_cluster_list[,1]
a_cluster_list= a_cluster_list[1:cluster_list_lengths_max]
a_cluster_list= as.character(a_cluster_list)
cluster_frame=cbind(cluster_frame,a_cluster_list)
colnames(cluster_frame)[i]= paste0("Cluster_",i)
}
}else{
cluster_frame= t(data.frame(unlist(cluster_list)))
cluster_frame= rbind(cluster_frame, cluster_frame)
row.names(cluster_frame)= 1:2
colnames(cluster_frame)= paste0("Cluster_",1:ncol(cluster_frame))
}
output= as.data.frame(cluster_frame)
output= as.data.frame(apply(output, 2, function(x){
gsub("[(|)]", "_", x)})) #as parenthesis treated as regex... get rid of.
exp_design_frame= output
output
get.cluster.titles(exp_design_frame)
cluster_names= get.cluster.titles(exp_design_frame)
cluster_names
remove.packages("sampleclusteR")
library(sampleclusteR)
concise= T
sdrf_loc= "https://ftp.ebi.ac.uk/biostudies/fire/E-GEOD-/882/E-GEOD-60882/Files/E-GEOD-60882.sdrf.txt"
#import sdrf metadata frame
metadata= read.delim(sdrf_loc, sep= "\t", header = T)
metadata[is.na(metadata)]= ""
#get the sample names
sample_source= metadata$Source.Name
#remove uneccessary columns
metadata= metadata[!grepl("id|file|accession|source[.]Name|scan[.]|comment[.]", colnames(metadata),
ignore.case= T)]
#cols_all_unique= apply(metadata, 2, function(x){
#  round(length(x)*broad_cluster_thres) > length(unique(x)) &
#    length(unique(x)) != 1
#cut down on redundancy- select columns where the are multiple values
cols_all_unique= apply(metadata, 2, function(x){
length(unique(x)) != 1
})
cluster_frame= metadata[,cols_all_unique]
#then remove columns where the same value is provided for a given row
nonredundant_col_indices= as.list(apply(cluster_frame, 1, function(x){which(!duplicated(x))}))
nonredundant_col_indices= unique(unlist(nonredundant_col_indices))
cluster_frame= cluster_frame[, nonredundant_col_indices]
#drop columns with sample ids or file ids to make automated clusters more
#readable
cols_to_keep= colnames(cluster_frame)
cluster_frame= metadata[,cols_to_keep]
#append column name i.e. append original column name from sdrf metadata table
for(i in 1:ncol(cluster_frame)){
append_col= colnames(cluster_frame)[i]
append_col= gsub("characteristics.|factor.value",
"",
append_col,
ignore.case = T)
append_col= gsub("[.]",
"_",
append_col,
ignore.case = T)
#upper case first letter
append_col=
paste0(toupper(substr(append_col,1,1)),
substr(append_col,2,nchar(append_col)))
append_col= gsub("^_|_$", "", append_col)
append_col= paste0(append_col, ":_")
cluster_frame[,i]= gsub(" ", "_", paste0(append_col, cluster_frame[,i],
sep= "_"))
}
row.names(cluster_frame)= 1:nrow(cluster_frame)
clustered_frame= cluster.metadata.frame(cluster_frame,
concise= concise)
library(sampleclusteR)
#import sdrf metadata frame
metadata= read.delim(sdrf_loc, sep= "\t", header = T)
metadata[is.na(metadata)]= ""
#get the sample names
sample_source= metadata$Source.Name
#remove uneccessary columns
metadata= metadata[!grepl("id|file|accession|source[.]Name|scan[.]|comment[.]", colnames(metadata),
ignore.case= T)]
#cols_all_unique= apply(metadata, 2, function(x){
#  round(length(x)*broad_cluster_thres) > length(unique(x)) &
#    length(unique(x)) != 1
#cut down on redundancy- select columns where the are multiple values
cols_all_unique= apply(metadata, 2, function(x){
length(unique(x)) != 1
})
cluster_frame= metadata[,cols_all_unique]
#then remove columns where the same value is provided for a given row
nonredundant_col_indices= as.list(apply(cluster_frame, 1, function(x){which(!duplicated(x))}))
nonredundant_col_indices= unique(unlist(nonredundant_col_indices))
cluster_frame= cluster_frame[, nonredundant_col_indices]
#drop columns with sample ids or file ids to make automated clusters more
#readable
cols_to_keep= colnames(cluster_frame)
cluster_frame= metadata[,cols_to_keep]
#append column name i.e. append original column name from sdrf metadata table
for(i in 1:ncol(cluster_frame)){
append_col= colnames(cluster_frame)[i]
append_col= gsub("characteristics.|factor.value",
"",
append_col,
ignore.case = T)
append_col= gsub("[.]",
"_",
append_col,
ignore.case = T)
#upper case first letter
append_col=
paste0(toupper(substr(append_col,1,1)),
substr(append_col,2,nchar(append_col)))
append_col= gsub("^_|_$", "", append_col)
append_col= paste0(append_col, ":_")
cluster_frame[,i]= gsub(" ", "_", paste0(append_col, cluster_frame[,i],
sep= "_"))
}
row.names(cluster_frame)= 1:nrow(cluster_frame)
clustered_frame= cluster.metadata.frame(cluster_frame,
concise= concise)
clustered_frame$sample= sample_source
clustered_frame
#import sdrf metadata frame
metadata= read.delim(sdrf_loc, sep= "\t", header = T)
metadata[is.na(metadata)]= ""
#get the sample names
sample_source= metadata$Source.Name
#remove uneccessary columns
metadata= metadata[!grepl("id|file|accession|source[.]Name|scan[.]|comment[.]", colnames(metadata),
ignore.case= T)]
#cols_all_unique= apply(metadata, 2, function(x){
#  round(length(x)*broad_cluster_thres) > length(unique(x)) &
#    length(unique(x)) != 1
#cut down on redundancy- select columns where the are multiple values
cols_all_unique= apply(metadata, 2, function(x){
length(unique(x)) != 1
})
cluster_frame= metadata[,cols_all_unique]
#then remove columns where the same value is provided for a given row
nonredundant_col_indices= as.list(apply(cluster_frame, 1, function(x){which(!duplicated(x))}))
nonredundant_col_indices= unique(unlist(nonredundant_col_indices))
cluster_frame= cluster_frame[, nonredundant_col_indices]
#drop columns with sample ids or file ids to make automated clusters more
#readable
cols_to_keep= colnames(cluster_frame)
cluster_frame= metadata[,cols_to_keep]
#append column name i.e. append original column name from sdrf metadata table
for(i in 1:ncol(cluster_frame)){
append_col= colnames(cluster_frame)[i]
append_col= gsub("characteristics.|factor.value",
"",
append_col,
ignore.case = T)
append_col= gsub("[.]",
"_",
append_col,
ignore.case = T)
#upper case first letter
append_col=
paste0(toupper(substr(append_col,1,1)),
substr(append_col,2,nchar(append_col)))
append_col= gsub("^_|_$", "", append_col)
append_col= paste0(append_col, ":_")
cluster_frame[,i]= gsub(" ", "_", paste0(append_col, cluster_frame[,i],
sep= "_"))
}
row.names(cluster_frame)= 1:nrow(cluster_frame)
cluster.metadata.frame(cluster_frame,
concise= concise)
