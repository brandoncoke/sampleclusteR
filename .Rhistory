#prior_array= prior_array.to_numpy()
#upper quartile
#upper_quart= np.percentile(prior_array, 75)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] >= upper_quart]
#lower quartile
#lower_quart= np.percentile(prior_array, 25)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] <= lower_quart]
#tried quantile regression on genomic only- bad bad bad
#sdf_data= sdf_data.dropna(axis=0)
#y= sdf_data['min_to_be_sig']
#y= y.to_numpy()
##y= y.argsort()
#y= pd.qcut(y, 4, labels= False)
#y[y == 2]= 1
#y[y == 3]= 2
#y= pd.qcut(y, 2, labels= False)
#sanity checy prior dist was still bimodial no dip test in python...
#we using python now ðŸ™‚ ðŸ”«. At least I can use emojis
import numpy as np
import sklearn as sk #pip install scikit-learn
from sklearn.ensemble import RandomForestRegressor#
from sklearn.model_selection import cross_val_score, RepeatedKFold, cross_val_predict, train_test_split
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVR
import matplotlib as mpl
#parameters for pretty plots
mpl.rcParams['axes.spines.right'] = False
mpl.rcParams['axes.spines.top'] = False
mpl.rcParams.update({'font.size': 12})
mpl.rcParams['figure.figsize'] = 12, 7 #alter x and y ratio for export
import matplotlib.pyplot as plt
import os
################################################################################
#Load and create SVM model
################################################################################
if os.name == 'nt':
sdf_data= pd.read_csv("C:/Users/bc790/Documents/csv/sklearn_frames/input_regression.csv")
else:
sdf_data= pd.read_csv("/mnt/c/Users/bc790/Documents/csv/sklearn_frames/input_regression.csv")
#if os.name == 'nt':
#  sdf_data= pd.read_csv("C:/Users/bc790/Documents/csv/sklearn_frames/input_regression_alt.csv")
#else:
#  sdf_data= pd.read_csv("/mnt/c/Users/bc790/Documents/csv/sklearn_frames/input_regression_alt.csv")
key_features= ["intron_max_ARE", "min_max_delta_cds_length",
"max_GC_rich_intron","intron_min_ARE","max_cds_length","min_GC_rich_intron",
"AP_sites","AP_prox_distal_detla","promoters_count","TSS_counts",
"UTR_5_min_ARE","max_utr3_length","RBMX_UTR3_counts","UTR_3_max_ARE",
"APA_UTR3_counts","max_MELP_cds","high_propensity","intron_present","intronic_AP_sites", "gene"]
key_features.append("min_to_be_sig")
key_features= [i for i in key_features if i in sdf_data.columns]
#sdf_data= sdf_data[key_features]
sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] > 0]
#filter genes with variable cdf values- sd in 80th percentile
sdf_data= sdf_data.loc[sdf_data['sd'] < np.quantile(sdf_data['sd'], 0.9)]
y= sdf_data['min_to_be_sig']
y_full= y
#y= pd.qcut(y, 4, labels= False)
#y[y == 2]= 1
#y[y == 3]= 2
h_lines= np.quantile(y_full, [.25,.5,.75])
#sanity check bimodial
fig, ax = plt.subplots(figsize=(20, 12.5))
plt.hist(y_full, bins= 100)
plt.axvline(h_lines[0], color='r', linestyle='-')
plt.axvline(h_lines[1], color='r', linestyle='-')
plt.axvline(h_lines[2], color='r', linestyle='-')
plt.show()
hot_encoded_cols_filter=  ['RG4_motif', "TOP_motif", "destablising_motif_UTR3",
"utr5_present", "utr3_present", "introns_present",
"lncRNA", "kozac", "intronic_AP_sites"]
hot_encoded_cols= [i for i in hot_encoded_cols_filter if i in sdf_data.columns]
numeric_cols= [i for i in sdf_data.columns if i not in hot_encoded_cols_filter]
transformer = make_column_transformer(
(OneHotEncoder(
handle_unknown='error', #you got binary values to deal with
categories='auto',  # Categories per feature
drop=None, # Whether to drop one of the features
sparse=True # Will return sparse matrix if set True
),
hot_encoded_cols),
remainder='passthrough')
X= sdf_data.drop('gene', axis= 1)
X= X.drop('sd', axis= 1)
X= X.drop('min_to_be_sig', axis= 1)
X = transformer.fit_transform(X)
x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,
random_state=50)
################################################################################
#Load and create SVM model
################################################################################
classifier= SVR(kernel= 'poly')
classifier= RandomForestRegressor()
#from sklearn.neural_network import MLPRegressor
#classifier= MLPRegressor()
#from catboost import CatBoostRegressor
#classifier= CatBoostRegressor()
classifier.fit(x_train, y_train)
y_pred_with_ability = classifier.predict(x_test)
R2_with_ability = r2_score(y_test, y_pred_with_ability)
R2_with_ability
##JUNK used ml data input then merge with prior frame and messed up- awful accuracy without APA and genomic features
#merge prior to features frame
#prior_frame= pd.read_csv("C:/Users/bc790/Documents/csv/min_to_be_sig.csv")
#sdf_data= sdf_data.merge(prior_frame, left_on= 'gene',
#right_on= 'gene')
#prior_frame= prior_frame.rename(columns= {'hgnc_symbol':'gene'})
#prior_frame= pd.read_table("C:/Users/bc790/Documents/csv/priors.tsv")
#prior_frame= prior_frame.rename(columns= {'Gene_Name':'gene'})
#prior_frame= prior_frame.rename(columns= {'DE_Prior_Rank':'min_to_be_sig'})
#prior_frame= prior_frame.iloc[: , [3,4]]
#LOOK HERE FILTER VARIABLE PRIORS
#sdf_data= sdf_data.loc[sdf_data['sd'] <= 0.05]
#LOOK HERE
#separate per perecentile
#prior_array= sdf_data['min_to_be_sig']
#prior_array= prior_array.to_numpy()
#upper quartile
#upper_quart= np.percentile(prior_array, 75)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] >= upper_quart]
#lower quartile
#lower_quart= np.percentile(prior_array, 25)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] <= lower_quart]
#tried quantile regression on genomic only- bad bad bad
#sdf_data= sdf_data.dropna(axis=0)
#y= sdf_data['min_to_be_sig']
#y= y.to_numpy()
##y= y.argsort()
#y= pd.qcut(y, 4, labels= False)
#y[y == 2]= 1
#y[y == 3]= 2
#y= pd.qcut(y, 2, labels= False)
#sanity checy prior dist was still bimodial no dip test in python...
#we using python now ðŸ™‚ ðŸ”«. At least I can use emojis
import numpy as np
import sklearn as sk #pip install scikit-learn
from sklearn.ensemble import RandomForestRegressor#
from sklearn.model_selection import cross_val_score, RepeatedKFold, cross_val_predict, train_test_split
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVR
import matplotlib as mpl
#parameters for pretty plots
mpl.rcParams['axes.spines.right'] = False
mpl.rcParams['axes.spines.top'] = False
mpl.rcParams.update({'font.size': 12})
mpl.rcParams['figure.figsize'] = 12, 7 #alter x and y ratio for export
import matplotlib.pyplot as plt
import os
################################################################################
#Load and create SVM model
################################################################################
if os.name == 'nt':
sdf_data= pd.read_csv("C:/Users/bc790/Documents/csv/sklearn_frames/input_regression.csv")
else:
sdf_data= pd.read_csv("/mnt/c/Users/bc790/Documents/csv/sklearn_frames/input_regression.csv")
#if os.name == 'nt':
#  sdf_data= pd.read_csv("C:/Users/bc790/Documents/csv/sklearn_frames/input_regression_alt.csv")
#else:
#  sdf_data= pd.read_csv("/mnt/c/Users/bc790/Documents/csv/sklearn_frames/input_regression_alt.csv")
key_features= ["intron_max_ARE", "min_max_delta_cds_length",
"max_GC_rich_intron","intron_min_ARE","max_cds_length","min_GC_rich_intron",
"AP_sites","AP_prox_distal_detla","promoters_count","TSS_counts",
"UTR_5_min_ARE","max_utr3_length","RBMX_UTR3_counts","UTR_3_max_ARE",
"APA_UTR3_counts","max_MELP_cds","high_propensity","intron_present","intronic_AP_sites", "gene"]
key_features.append("min_to_be_sig")
key_features= [i for i in key_features if i in sdf_data.columns]
#sdf_data= sdf_data[key_features]
sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] > 0]
#filter genes with variable cdf values- sd in 80th percentile
#sdf_data= sdf_data.loc[sdf_data['sd'] < np.quantile(sdf_data['sd'], 0.9)]
y= sdf_data['min_to_be_sig']
y_full= y
#y= pd.qcut(y, 4, labels= False)
#y[y == 2]= 1
#y[y == 3]= 2
h_lines= np.quantile(y_full, [.25,.5,.75])
#sanity check bimodial
fig, ax = plt.subplots(figsize=(20, 12.5))
plt.hist(y_full, bins= 100)
plt.axvline(h_lines[0], color='r', linestyle='-')
plt.axvline(h_lines[1], color='r', linestyle='-')
plt.axvline(h_lines[2], color='r', linestyle='-')
plt.show()
hot_encoded_cols_filter=  ['RG4_motif', "TOP_motif", "destablising_motif_UTR3",
"utr5_present", "utr3_present", "introns_present",
"lncRNA", "kozac", "intronic_AP_sites"]
hot_encoded_cols= [i for i in hot_encoded_cols_filter if i in sdf_data.columns]
numeric_cols= [i for i in sdf_data.columns if i not in hot_encoded_cols_filter]
transformer = make_column_transformer(
(OneHotEncoder(
handle_unknown='error', #you got binary values to deal with
categories='auto',  # Categories per feature
drop=None, # Whether to drop one of the features
sparse=True # Will return sparse matrix if set True
),
hot_encoded_cols),
remainder='passthrough')
X= sdf_data.drop('gene', axis= 1)
X= X.drop('sd', axis= 1)
X= X.drop('min_to_be_sig', axis= 1)
X = transformer.fit_transform(X)
x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.3,
random_state=50)
################################################################################
#Load and create SVM model
################################################################################
classifier= SVR(kernel= 'poly')
classifier= RandomForestRegressor()
#from sklearn.neural_network import MLPRegressor
#classifier= MLPRegressor()
#from catboost import CatBoostRegressor
#classifier= CatBoostRegressor()
classifier.fit(x_train, y_train)
y_pred_with_ability = classifier.predict(x_test)
R2_with_ability = r2_score(y_test, y_pred_with_ability)
R2_with_ability
##JUNK used ml data input then merge with prior frame and messed up- awful accuracy without APA and genomic features
#merge prior to features frame
#prior_frame= pd.read_csv("C:/Users/bc790/Documents/csv/min_to_be_sig.csv")
#sdf_data= sdf_data.merge(prior_frame, left_on= 'gene',
#right_on= 'gene')
#prior_frame= prior_frame.rename(columns= {'hgnc_symbol':'gene'})
#prior_frame= pd.read_table("C:/Users/bc790/Documents/csv/priors.tsv")
#prior_frame= prior_frame.rename(columns= {'Gene_Name':'gene'})
#prior_frame= prior_frame.rename(columns= {'DE_Prior_Rank':'min_to_be_sig'})
#prior_frame= prior_frame.iloc[: , [3,4]]
#LOOK HERE FILTER VARIABLE PRIORS
#sdf_data= sdf_data.loc[sdf_data['sd'] <= 0.05]
#LOOK HERE
#separate per perecentile
#prior_array= sdf_data['min_to_be_sig']
#prior_array= prior_array.to_numpy()
#upper quartile
#upper_quart= np.percentile(prior_array, 75)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] >= upper_quart]
#lower quartile
#lower_quart= np.percentile(prior_array, 25)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] <= lower_quart]
#tried quantile regression on genomic only- bad bad bad
#sdf_data= sdf_data.dropna(axis=0)
#y= sdf_data['min_to_be_sig']
#y= y.to_numpy()
##y= y.argsort()
#y= pd.qcut(y, 4, labels= False)
#y[y == 2]= 1
#y[y == 3]= 2
#y= pd.qcut(y, 2, labels= False)
#sanity checy prior dist was still bimodial no dip test in python...
#we using python now ðŸ™‚ ðŸ”«. At least I can use emojis
import numpy as np
import sklearn as sk #pip install scikit-learn
from sklearn.ensemble import RandomForestRegressor#
from sklearn.model_selection import cross_val_score, RepeatedKFold, cross_val_predict, train_test_split
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVR
import matplotlib as mpl
#parameters for pretty plots
mpl.rcParams['axes.spines.right'] = False
mpl.rcParams['axes.spines.top'] = False
mpl.rcParams.update({'font.size': 12})
mpl.rcParams['figure.figsize'] = 12, 7 #alter x and y ratio for export
import matplotlib.pyplot as plt
import os
################################################################################
#Load and create SVM model
################################################################################
if os.name == 'nt':
sdf_data= pd.read_csv("C:/Users/bc790/Documents/csv/sklearn_frames/input_regression.csv")
else:
sdf_data= pd.read_csv("/mnt/c/Users/bc790/Documents/csv/sklearn_frames/input_regression.csv")
#if os.name == 'nt':
#  sdf_data= pd.read_csv("C:/Users/bc790/Documents/csv/sklearn_frames/input_regression_alt.csv")
#else:
#  sdf_data= pd.read_csv("/mnt/c/Users/bc790/Documents/csv/sklearn_frames/input_regression_alt.csv")
key_features= ["intron_max_ARE", "min_max_delta_cds_length",
"max_GC_rich_intron","intron_min_ARE","max_cds_length","min_GC_rich_intron",
"AP_sites","AP_prox_distal_detla","promoters_count","TSS_counts",
"UTR_5_min_ARE","max_utr3_length","RBMX_UTR3_counts","UTR_3_max_ARE",
"APA_UTR3_counts","max_MELP_cds","high_propensity","intron_present","intronic_AP_sites", "gene"]
key_features.append("min_to_be_sig")
key_features= [i for i in key_features if i in sdf_data.columns]
#sdf_data= sdf_data[key_features]
sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] > 0]
#filter genes with variable cdf values- sd in 80th percentile
#sdf_data= sdf_data.loc[sdf_data['sd'] < np.quantile(sdf_data['sd'], 0.9)]
y= sdf_data['min_to_be_sig']
y_full= y
#y= pd.qcut(y, 4, labels= False)
#y[y == 2]= 1
#y[y == 3]= 2
h_lines= np.quantile(y_full, [.25,.5,.75])
#sanity check bimodial
fig, ax = plt.subplots(figsize=(20, 12.5))
plt.hist(y_full, bins= 100)
plt.axvline(h_lines[0], color='r', linestyle='-')
plt.axvline(h_lines[1], color='r', linestyle='-')
plt.axvline(h_lines[2], color='r', linestyle='-')
plt.show()
hot_encoded_cols_filter=  ['RG4_motif', "TOP_motif", "destablising_motif_UTR3",
"utr5_present", "utr3_present", "introns_present",
"lncRNA", "kozac", "intronic_AP_sites"]
hot_encoded_cols= [i for i in hot_encoded_cols_filter if i in sdf_data.columns]
numeric_cols= [i for i in sdf_data.columns if i not in hot_encoded_cols_filter]
transformer = make_column_transformer(
(OneHotEncoder(
handle_unknown='error', #you got binary values to deal with
categories='auto',  # Categories per feature
drop=None, # Whether to drop one of the features
sparse=True # Will return sparse matrix if set True
),
hot_encoded_cols),
remainder='passthrough')
X= sdf_data.drop('gene', axis= 1)
X= X.drop('sd', axis= 1)
X= X.drop('min_to_be_sig', axis= 1)
X = transformer.fit_transform(X)
x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.4,
random_state=50)
################################################################################
#Load and create SVM model
################################################################################
classifier= SVR(kernel= 'poly')
classifier= RandomForestRegressor()
#from sklearn.neural_network import MLPRegressor
#classifier= MLPRegressor()
#from catboost import CatBoostRegressor
#classifier= CatBoostRegressor()
classifier.fit(x_train, y_train)
y_pred_with_ability = classifier.predict(x_test)
R2_with_ability = r2_score(y_test, y_pred_with_ability)
R2_with_ability
##JUNK used ml data input then merge with prior frame and messed up- awful accuracy without APA and genomic features
#merge prior to features frame
#prior_frame= pd.read_csv("C:/Users/bc790/Documents/csv/min_to_be_sig.csv")
#sdf_data= sdf_data.merge(prior_frame, left_on= 'gene',
#right_on= 'gene')
#prior_frame= prior_frame.rename(columns= {'hgnc_symbol':'gene'})
#prior_frame= pd.read_table("C:/Users/bc790/Documents/csv/priors.tsv")
#prior_frame= prior_frame.rename(columns= {'Gene_Name':'gene'})
#prior_frame= prior_frame.rename(columns= {'DE_Prior_Rank':'min_to_be_sig'})
#prior_frame= prior_frame.iloc[: , [3,4]]
#LOOK HERE FILTER VARIABLE PRIORS
#sdf_data= sdf_data.loc[sdf_data['sd'] <= 0.05]
#LOOK HERE
#separate per perecentile
#prior_array= sdf_data['min_to_be_sig']
#prior_array= prior_array.to_numpy()
#upper quartile
#upper_quart= np.percentile(prior_array, 75)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] >= upper_quart]
#lower quartile
#lower_quart= np.percentile(prior_array, 25)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] <= lower_quart]
#tried quantile regression on genomic only- bad bad bad
#sdf_data= sdf_data.dropna(axis=0)
#y= sdf_data['min_to_be_sig']
#y= y.to_numpy()
##y= y.argsort()
#y= pd.qcut(y, 4, labels= False)
#y[y == 2]= 1
#y[y == 3]= 2
#y= pd.qcut(y, 2, labels= False)
#sanity checy prior dist was still bimodial no dip test in python...
#we using python now ðŸ™‚ ðŸ”«. At least I can use emojis
import numpy as np
import sklearn as sk #pip install scikit-learn
from sklearn.ensemble import RandomForestRegressor#
from sklearn.model_selection import cross_val_score, RepeatedKFold, cross_val_predict, train_test_split
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVR
import matplotlib as mpl
#parameters for pretty plots
mpl.rcParams['axes.spines.right'] = False
mpl.rcParams['axes.spines.top'] = False
mpl.rcParams.update({'font.size': 12})
mpl.rcParams['figure.figsize'] = 12, 7 #alter x and y ratio for export
import matplotlib.pyplot as plt
import os
################################################################################
#Load and create SVM model
################################################################################
if os.name == 'nt':
sdf_data= pd.read_csv("C:/Users/bc790/Documents/csv/sklearn_frames/input_regression.csv")
else:
sdf_data= pd.read_csv("/mnt/c/Users/bc790/Documents/csv/sklearn_frames/input_regression.csv")
#if os.name == 'nt':
#  sdf_data= pd.read_csv("C:/Users/bc790/Documents/csv/sklearn_frames/input_regression_alt.csv")
#else:
#  sdf_data= pd.read_csv("/mnt/c/Users/bc790/Documents/csv/sklearn_frames/input_regression_alt.csv")
key_features= ["intron_max_ARE", "min_max_delta_cds_length",
"max_GC_rich_intron","intron_min_ARE","max_cds_length","min_GC_rich_intron",
"AP_sites","AP_prox_distal_detla","promoters_count","TSS_counts",
"UTR_5_min_ARE","max_utr3_length","RBMX_UTR3_counts","UTR_3_max_ARE",
"APA_UTR3_counts","max_MELP_cds","high_propensity","intron_present","intronic_AP_sites", "gene"]
key_features.append("min_to_be_sig")
key_features= [i for i in key_features if i in sdf_data.columns]
#sdf_data= sdf_data[key_features]
sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] > 0]
#filter genes with variable cdf values- sd in 90th percentile
sdf_data= sdf_data.loc[sdf_data['sd'] < np.quantile(sdf_data['sd'], 0.9)]
y= sdf_data['min_to_be_sig']
y_full= y
#y= pd.qcut(y, 4, labels= False)
#y[y == 2]= 1
#y[y == 3]= 2
h_lines= np.quantile(y_full, [.25,.5,.75])
#sanity check bimodial
fig, ax = plt.subplots(figsize=(20, 12.5))
plt.hist(y_full, bins= 100)
plt.axvline(h_lines[0], color='r', linestyle='-')
plt.axvline(h_lines[1], color='r', linestyle='-')
plt.axvline(h_lines[2], color='r', linestyle='-')
plt.show()
hot_encoded_cols_filter=  ['RG4_motif', "TOP_motif", "destablising_motif_UTR3",
"utr5_present", "utr3_present", "introns_present",
"lncRNA", "kozac", "intronic_AP_sites"]
hot_encoded_cols= [i for i in hot_encoded_cols_filter if i in sdf_data.columns]
numeric_cols= [i for i in sdf_data.columns if i not in hot_encoded_cols_filter]
transformer = make_column_transformer(
(OneHotEncoder(
handle_unknown='error', #you got binary values to deal with
categories='auto',  # Categories per feature
drop=None, # Whether to drop one of the features
sparse=True # Will return sparse matrix if set True
),
hot_encoded_cols),
remainder='passthrough')
X= sdf_data.drop('gene', axis= 1)
X= X.drop('sd', axis= 1)
X= X.drop('min_to_be_sig', axis= 1)
X = transformer.fit_transform(X)
x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.4,
random_state=50)
################################################################################
#Load and create SVM model
################################################################################
classifier= SVR(kernel= 'poly')
classifier= RandomForestRegressor()
#from sklearn.neural_network import MLPRegressor
#classifier= MLPRegressor()
#from catboost import CatBoostRegressor
#classifier= CatBoostRegressor()
classifier.fit(x_train, y_train)
y_pred_with_ability = classifier.predict(x_test)
R2_with_ability = r2_score(y_test, y_pred_with_ability)
R2_with_ability
##JUNK used ml data input then merge with prior frame and messed up- awful accuracy without APA and genomic features
#merge prior to features frame
#prior_frame= pd.read_csv("C:/Users/bc790/Documents/csv/min_to_be_sig.csv")
#sdf_data= sdf_data.merge(prior_frame, left_on= 'gene',
#right_on= 'gene')
#prior_frame= prior_frame.rename(columns= {'hgnc_symbol':'gene'})
#prior_frame= pd.read_table("C:/Users/bc790/Documents/csv/priors.tsv")
#prior_frame= prior_frame.rename(columns= {'Gene_Name':'gene'})
#prior_frame= prior_frame.rename(columns= {'DE_Prior_Rank':'min_to_be_sig'})
#prior_frame= prior_frame.iloc[: , [3,4]]
#LOOK HERE FILTER VARIABLE PRIORS
#sdf_data= sdf_data.loc[sdf_data['sd'] <= 0.05]
#LOOK HERE
#separate per perecentile
#prior_array= sdf_data['min_to_be_sig']
#prior_array= prior_array.to_numpy()
#upper quartile
#upper_quart= np.percentile(prior_array, 75)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] >= upper_quart]
#lower quartile
#lower_quart= np.percentile(prior_array, 25)
#sdf_data= sdf_data.loc[sdf_data['min_to_be_sig'] <= lower_quart]
#tried quantile regression on genomic only- bad bad bad
#sdf_data= sdf_data.dropna(axis=0)
#y= sdf_data['min_to_be_sig']
#y= y.to_numpy()
##y= y.argsort()
#y= pd.qcut(y, 4, labels= False)
#y[y == 2]= 1
#y[y == 3]= 2
#y= pd.qcut(y, 2, labels= False)
#sanity checy prior dist was still bimodial no dip test in python...
setwd("~")
sdrf_loc= "https://ftp.ebi.ac.uk/biostudies/fire/E-MTAB-/935/E-MTAB-11935/Files/E-MTAB-11935.sdrf.txt"
metadata= read.delim(sdrf_loc, sep= "\t", header = T)
metadata[is.na(metadata)]= ""
#get the sample names
sample_source= metadata$Source.Name
View(metadata)
a=read.csv("~/csv/ArrayExpress_benchmark_frame.csv")
a$automated_group == a$manual_group
sum(a$automated_group == a$manual_group)
bool= a$automated_group == a$manual_group
bool[is.na(bool)]= F
bool
sum(bool)
sum(bool)/nrow(a)
